{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big data means collecting, storing, and processing data at a large scale on multiple machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Challenges of Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Vast majority of work goes into feature engineering and selection, i.e preprocessing steps.\n",
    "2. Iteration: Modeling and analysis require multiple passes over the same data.\n",
    "3. Provide the same model in data applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Spark is an open source framework that combines an engine for distributing programs across clusters of machines with an elegant model for writing programs atop it.\n",
    "\n",
    "Features:\n",
    "\n",
    "1. Rather than relying on a rigid map-then-reduce format, its engine can execute a more general directed acyclic graph (DAG) of operators.\n",
    "2. it complements this capability with a rich set of transformations that enable users to express computation more naturally.\n",
    "3. Spark extends its predecessors with in-memory processing.\n",
    "4. Sitting atop the JVM, it can take advantage of many of the operational and debugging tools built for the Java stack.\n",
    "5. Spark boasts strong integration with the variety of tools in the Hadoop ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Analysis with Scala and Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important talents that one can develop as a data scientist is the ability to discover interesting and worthwhile problems in every phase of the data analytics lifecycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scala for Data Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning how to work with Spark in the same language in which the underlying framework is written (Scala) has a number of advantages:\n",
    "\n",
    "1. It reduces performance overhead.\n",
    "2. It gives you access to the latest and greatest.\n",
    "3. It will help you understand the Spark philosophy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Spark Programming Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark programming starts with a data set or few, usually residing in some form of distributed, persistent storage like the Hadoop Distributed File System (HDFS). Writing a Spark program typically consists of a few related steps:\n",
    "\n",
    "1. Defining a set of transformations on input data sets.\n",
    "2. Invoking actions that output the transformed data sets to persistent storage or return results to the driverâ€™s local memory.\n",
    "3. Running local computations that operate on the results computed in a distributed fashion. These can help you decide what transformations and actions to undertake next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general structure of the problem is something like this: we have a large collection of records from one or more source systems, and it is likely that some of the records refer to the same underlying entity, such as a customer, a patient, or the location of a business or an event. Identify the records that refers to the same entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started: The Spark Shell and SparkContext"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
